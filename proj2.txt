Project 2: Quantitative Research Log Analyzer
Description
A tool that parses and analyzes logs from simulated trading systems or research experiments, identifying patterns like error spikes or performance bottlenecks, with an interactive dashboard for exploratory analysis—mirroring support for quants in monitoring production correctness.

Problem and SolutionProblem: In quant firms, system logs from backtests or live trading accumulate vast unstructured data, making it hard to spot issues like latency anomalies or failed signals quickly, which can delay research iterations in a fast-paced industry.

Solution: Develop an analyzer that structures logs into queryable data, computes metrics (e.g., error rates), and alerts on thresholds, enabling 50% faster issue resolution in ad-hoc analyses, aligning with collaborative enhancements in research operations.Stacks to UsePython (log parsing and automation)
Pandas (structuring and querying log data)
NumPy (statistical analysis of metrics)
Streamlit (dashboard for filtering, visualization, and alerts)

Phase-by-Phase ImplementationEnvironment Setup and Data Generation: Set up with pip installs. Create synthetic logs (e.g., JSON lines with timestamps, error codes, latencies) using Python loops and random libraries. Use public log samples from Kaggle (e.g., "System Logs Dataset") for realism.
Log Parsing and Structuring: Write a Python function to read logs line-by-line, parse with regex or json.loads(). Convert to Pandas DataFrame (columns: timestamp, level, message, latency). Handle malformed lines gracefully.
Analysis and Metric Calculation: Use NumPy for aggregates like average latency (np.mean(df['latency'])) and percentiles (np.percentile(df['latency'], 95)). Filter errors with Pandas (df[df['level'] == 'ERROR']). Detect spikes via rolling std deviation.
Anomaly Detection and Alerting: Implement simple rules (e.g., if np.std(window) > threshold, flag). Add a function to generate summary reports as CSV exports.
Streamlit Interface Build: In main.py, add text input for log file paths or uploads. Display DataFrame previews, interactive filters (e.g., date range sliders), and charts (st.bar_chart for error counts by hour). Include a "Generate Report" button.
Quality Assurance and Scalability: Test on large logs (e.g., 100K lines) with timing benchmarks. Ensure clean code with comments and error handling. Deploy and share a live demo link.
Eqvilent-Specific Polish: Tie to quant workflows by including research-specific metrics (e.g., signal failure rates). Emphasize deep dives into complex logs, showcasing problem-solving for team collaboration.




# Quantitative Research Log Analyzer

**A production-grade internal tool for monitoring, analyzing, and exploring quantitative trading/research system logs**

![Streamlit Dashboard Preview](https://via.placeholder.com/800x400?text=Quantitative+Research+Log+Analyzer+Dashboard+Preview)  
*(Replace with your actual screenshot or deployed app preview)*

**Live Demo**: [https://your-username-quant-log-analyzer.streamlit.app](https://your-username-quant-log-analyzer.streamlit.app) *(Deploy on Streamlit Community Cloud and update link)*  
**GitHub Repository**: [https://github.com/your-username/quant_log_analyzer](https://github.com/your-username/quant_log_analyzer)

## Project Overview

This project is a fully functional **internal utility tool** built in Python to support quantitative researchers and developers in a high-frequency/quantitative trading environment (e.g., firms like Eqvilent).

It demonstrates the exact skills required for a **Python Analyst / Research Support role**:
- Discovering, validating, and cleaning large log datasets
- Monitoring production/research systems for correctness
- Performing ad-hoc exploratory analysis
- Building clean, robust automation and visualization tools

The tool processes unstructured JSONL logs, structures them, computes key metrics, detects anomalies, and provides an interactive **Streamlit dashboard** for quants and engineers.

## Tech Stack
- **Python** – core language with clean, readable, production-quality code
- **Pandas** – data structuring, filtering, grouping
- **NumPy** – efficient statistical calculations (percentiles, z-scores)
- **Matplotlib** – visualizations
- **Streamlit** – interactive web dashboard with file upload, filters, and live updates

## Project Phases & Accomplishments

### Phase 1: Generating Realistic Synthetic Dataset
- Created ~5,000 realistic log entries simulating a busy trading/research day
- Used weighted log levels (INFO dominant, ERROR rare), latency spikes, quant-specific fields (signal_id, error_code, asset, component)
- Implemented natural activity bursts and timestamp progression
- Saved as **JSON Lines (JSONL)** format – industry standard for streaming logs

### Phase 2: Log Parsing and Structuring
- Built robust line-by-line parser with graceful handling of malformed JSON
- Converted to typed **Pandas DataFrame** (datetime timestamps, numeric latency)
- Added comprehensive validation checks (missing values, duplicates, timestamp gaps, outliers)
- Saved cleaned data as **Parquet** for fast reuse

### Phase 3: Analysis and Metric Calculation
- Implemented comprehensive monitoring metrics using Pandas + NumPy:
  - Error/warning rates, latency statistics (mean, p95, p99)
  - Per-component and per-asset error breakdowns
  - Signal failure rate estimation
- Created hourly temporal summaries and basic rolling anomaly flagging
- Exported structured analysis reports (JSON)

### Phase 4: Anomaly Detection and Alerting
- Developed multi-type anomaly detection:
  - Latency z-score spikes
  - Error rate bursts (mean + 2σ threshold)
  - Component failure concentration
- Generated structured, severity-tagged alerts
- Automated timestamped report export (JSON + CSV) for team sharing or monitoring integration

### Phase 5: Interactive Streamlit Dashboard
- Built fully interactive web app with:
  - File upload (JSONL) or default synthetic logs
  - Live sidebar metrics (error count, latency percentiles)
  - Multi-select filters (log level, component, time range slider)
  - Robust visualizations that gracefully handle empty/no-data states:
    - Log level distribution (bar chart)
    - Error count by hour (bar)
    - Latency distribution (histogram)
    - Top components breakdown (pie)
  - Real-time anomaly alerts with severity indicators
  - One-click report generation

The dashboard is defensive-coded: no crashes on any filter combination, with clear user feedback when charts are not applicable.

## Why This Project Stands Out for Quant Research Support Roles
- Directly mirrors real-world tasks: cleaning messy production logs, monitoring system health, enabling fast researcher insights
- Emphasizes **code quality**, **attention to detail**, and **robustness** – critical in finance/research environments
- Uses **production-grade formats and patterns** (JSONL → Parquet, streaming parsing, graceful degradation)
- Delivers a polished, deployable internal tool that quants would actually use

## How to Run Locally
```bash
git clone https://github.com/your-username/quant_log_analyzer.git
cd quant_log_analyzer
pip install pandas numpy matplotlib streamlit
streamlit run app.py

